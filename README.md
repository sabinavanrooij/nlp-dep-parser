# nlp-dep-parser
NLP project on dependency parsers

<b>Final Report</b>: https://www.overleaf.com/12707057qsjgmmyjnswh

Requirements for the report: https://github.com/tdeoskar/NLP1-2017/blob/master/project-reqs.md



<b> TO DO: </b>

- Make plot of one sentence over epochs <i>Done</i>

- Make plot of loss over epochs <i>Done</i>

- Train the model in English and Dutch <i>Done</i>

- Parse sentences in test set <i>Done</i>

- Write results  

- Write discussion and conclusion



(- Handle multiple cycles in the MST algo)


Milestone:

<b>Dependency-data</b>

Reading in and writing out text from the CONLL-U file type. <i>Done</i>

Replace all the words in your training file that occur just once with the word <unk>. <i>Done</i>

w2i, t2i, and l2i dicts. And inverse: i2w, i2t, i2l <i>Done</i>

Remove lines from .conllu file that have non integers as indices <i>Done</i>

<b>MST</b>

<i>In progress</i>

<b>LSTM</b>

Embedding layer for words <i>Done</i>

Support for optional pretrained word embeddings <i>Done</i>

Embedding layer for POS tags <i>Done</i>

Support for optional pretrained tag embeddings <i>Done</i>

Concatenate these word embeddings <i>Done</i>

LSTM layer <i>Done</i>


